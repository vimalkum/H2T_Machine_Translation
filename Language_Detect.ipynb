{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimalkum/H2T_Machine_Translation/blob/master/Language_Detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w81omYeAhsCM",
        "colab_type": "code",
        "outputId": "b9856897-fc32-492e-a968-e8df9b1bf634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('indian')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "for ids in nltk.corpus.indian.fileids():\n",
        "  print(ids)\n",
        "def Hin_Corpus():\n",
        "  corpus=[]\n",
        "  for sent in nltk.corpus.indian.sents('hindi.pos'):\n",
        "    corpus.append(sent)\n",
        "  return corpus\n",
        "def Bangla_Corpus():\n",
        "  corpus=[]\n",
        "  for sent in nltk.corpus.indian.sents('bangla.pos'):\n",
        "    corpus.append(sent)\n",
        "  return corpus\n",
        "\n",
        "def Eng_Corpus():\n",
        "  corpus=[]\n",
        "  #for ids in brown.categories():\n",
        "  for sent in brown.sents(categories=\"news\"):\n",
        "    corpus.append(sent)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/indian.zip.\n",
            "bangla.pos\n",
            "hindi.pos\n",
            "marathi.pos\n",
            "telugu.pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1eGz4ekkNT",
        "colab_type": "code",
        "outputId": "7dead0dd-5891-4867-d48f-7273523b8eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "Eng_corpus = Eng_Corpus()\n",
        "print(Eng_corpus[:5])\n",
        "Hin_corpus = Hin_Corpus()\n",
        "print(Hin_corpus[:5])\n",
        "Bangla_corpus = Bangla_Corpus()\n",
        "print(Bangla_corpus[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ['The', 'September-October', 'term', 'jury', 'had', 'been', 'charged', 'by', 'Fulton', 'Superior', 'Court', 'Judge', 'Durwood', 'Pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'Mayor-nominate', 'Ivan', 'Allen', 'Jr.', '.'], ['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.'], ['The', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', \"Georgia's\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']]\n",
            "[['पूर्ण', 'प्रतिबंध', 'हटाओ', ':', 'इराक'], ['संयुक्त', 'राष्ट्र', '।'], ['इराक', 'के', 'विदेश', 'मंत्री', 'ने', 'अमरीका', 'के', 'उस', 'प्रस्ताव', 'का', 'मजाक', 'उड़ाया', 'है', ',', 'जिसमें', 'अमरीका', 'ने', 'संयुक्त', 'राष्ट्र', 'के', 'प्रतिबंधों', 'को', 'इराकी', 'नागरिकों', 'के', 'लिए', 'कम', 'हानिकारक', 'बनाने', 'के', 'लिए', 'कहा', 'है', '।'], ['विदेश', 'मंत्री', 'का', 'कहना', 'है', 'कि', 'चूंकि', 'बगदाद', 'संयुक्त', 'राष्ट्र', 'की', 'मांगों', 'का', 'पालन', 'करते', 'हुए', 'अपने', 'भारी', 'विनाशकारी', 'हथियारों', 'को', 'नष्ट', 'कर', 'रहा', 'है', '।'], ['लिहाजा', 'प्रतिबंधों', 'को', 'पूर्ण', 'रूप', 'से', 'उठा', 'दिया', 'जाना', 'चाहिए', '।']]\n",
            "[['মহিষের', 'সন্তান', ':', 'তোড়া', 'উপজাতি', '৷'], ['বাসস্থান-ঘরগৃহস্থালি', 'তোড়া', 'ভাষায়', 'গ্রামকেও', 'বলে', '`', 'মোদ', \"'\", '৷'], ['মোদের', 'আয়তন', 'খুব', 'বড়ো', 'নয়', '৷'], ['প্রতি', 'মোদে', 'আছে', 'কিছু', 'কুঁড়েঘর', ',', 'সাধারণ', 'মহিষশালা', '৷'], ['আর', 'গ্রামের', 'বাইরে', 'থাকে', 'ডেয়ারি-মন্দির', '৷']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLVGILfymlwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "def BiGram_Prob(corpus):\n",
        "  tokens=[]\n",
        "  for sent in corpus:\n",
        "    for tok in sent:\n",
        "      tokens.append(tok.lower())\n",
        "  #print(len(tokens))\n",
        "  freq = nltk.FreqDist(w.lower() for w in tokens)\n",
        "  bigrams=[(tokens[i],tokens[i+1]) for i in range(0,len(tokens)-1)]\n",
        "  #print(bigrams[:5])\n",
        "\n",
        "  count = Counter(bigrams)\n",
        "  for k in count.keys():\n",
        "    #print(k[0]+\" \"+k[1]+ \" \",k)\n",
        "    #if(freq[k[1]]):\n",
        "    count[k]=count[k]/freq[k[1]]\n",
        "\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38rl7Jgom6Pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Eng_prob = BiGram_Prob(Eng_corpus)\n",
        "Hin_prob = BiGram_Prob(Hin_corpus)\n",
        "Bangla_prob = BiGram_Prob(Bangla_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nRt9JRKeM-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def Prob_Calc(prob_table,sent):\n",
        "  tokens=sent.split(\" \")\n",
        "  bigrams=[(tokens[i],tokens[i+1]) for i in range(0,len(tokens)-1)]\n",
        "  prob=0\n",
        "  for w in bigrams:\n",
        "    #print(w,prob_table[w])\n",
        "    if(prob_table[w]!=0):\n",
        "      prob=prob+math.log(prob_table[w],10)\n",
        "  return prob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAKyKbaj9TN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(sent):\n",
        "  l1=[]\n",
        "  l1.append(Prob_Calc(Eng_prob,sent))\n",
        "  l1.append(Prob_Calc(Hin_prob,sent))\n",
        "  l1.append(Prob_Calc(Bangla_prob,sent))\n",
        "  return l1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvLoa5chjNZW",
        "colab_type": "code",
        "outputId": "4cc8b8e0-f094-4b56-9328-aa093d59314f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(testing (\"इराक के विदेश मंत्री ने अमरीका का मजाक उड़ाया है\".lower()))\n",
        "print(testing('মহিষের সন্তান : তোড়া উপজাতি ৷'.lower()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, -8.676818785425274, 0]\n",
            "[0, 0, -4.957703041548831]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXoM59ZpjWgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}